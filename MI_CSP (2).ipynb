{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmHEPHouS4w1"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from scipy import signal\n",
        "from scipy.signal import butter, sosfilt, sosfreqz\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "eEPqAHTHS-BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HT827VXS4w5"
      },
      "outputs": [],
      "source": [
        "## Motor Imagery dataset load\n",
        "\n",
        "mat = scipy.io.loadmat('drive/MyDrive/MI_cnt_train.mat')\n",
        "tr_cnt_ = np.array(mat.get('cnt1'))\n",
        "\n",
        "mat_Y = scipy.io.loadmat('drive/MyDrive/MI_cnt_train_label.mat')\n",
        "tr_Label = np.array(mat_Y.get('label'))\n",
        "\n",
        "mat_m = scipy.io.loadmat('drive/MyDrive/MI_cnt_train_marker.mat')\n",
        "tr_marker = np.array(mat_m.get('marker'))\n",
        "\n",
        "mat = scipy.io.loadmat('drive/MyDrive/MI_cnt_test.mat')\n",
        "te_cnt_ = np.array(mat.get('cnt1'))\n",
        "\n",
        "mat_Y = scipy.io.loadmat('drive/MyDrive/MI_cnt_test_label.mat')\n",
        "te_Label = np.array(mat_Y.get('label'))\n",
        "\n",
        "mat_m = scipy.io.loadmat('drive/MyDrive/MI_cnt_test_marker.mat')\n",
        "te_marker = np.array(mat_m.get('marker'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIfuogIGS4w7"
      },
      "outputs": [],
      "source": [
        "CH = ['Fp1','Fp2','F7','F3','Fz','F4','F8','FC5','FC1','FC2','FC6', \n",
        "      'T7','C3','Cz','C4','T8','TP9','CP5','CP1','CP2','CP6','TP10',\n",
        "      'P7','P3','Pz','P4','P8','PO9''O1','Oz','O2','PO10','FC3','FC4',\n",
        "      'C5','C1','C2','C6','CP3','CPz','CP4','P1','P2','POz','FT9','FTT9h',\n",
        "      'TTP7h','TP7','TPP9h','FT10','FTT10h','TPP8h','TP8','TPP10h','F9',\n",
        "      'F10','AF7','AF3','AF4','AF8','PO3','PO4']\n",
        "\n",
        "print(np.shape(tr_cnt_))\n",
        "print(np.shape(tr_Label))\n",
        "print(np.shape(tr_marker))\n",
        "\n",
        "print(len(tr_cnt_)/60/100, \"minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6WV7QVCS4w9"
      },
      "source": [
        "- We can use heuristic parameters (e.g., band, time-interval, channel) based on out prior knowledge\n",
        "- Once you decided to use the general parameters, it should be applied to all subjects\n",
        "- Note that we can find better parameters (or maybe subject-specific parameters) from the validation dataset (not from test dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeI5ToZ2S4xA"
      },
      "outputs": [],
      "source": [
        "band = [5, 30]\n",
        "interval = [150, 350]\n",
        "\n",
        "# channel selection \n",
        "ch_idx = list()\n",
        "ch_name = list()\n",
        "for i in CH:\n",
        "    '''\n",
        "    if 'C' in i: # you can select central area\n",
        "        ch_idx.append(CH.index(i))\n",
        "        ch_name.append(CH[CH.index(i)])        \n",
        "    '''\n",
        "    if 1: # or use entire channel\n",
        "        ch_idx.append(CH.index(i))\n",
        "        ch_name.append(CH[CH.index(i)])\n",
        "  \n",
        "# Here we select the channels\n",
        "\n",
        "if not ch_idx:\n",
        "    tr_cnt = tr_cnt_[:, ch_idx]\n",
        "    te_cnt = te_cnt_[:, ch_idx]\n",
        "\n",
        "print(f\"{len(ch_name)} channels were selected\" )\n",
        "np.shape(te_cnt_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oIvALZ9S4xB"
      },
      "source": [
        "## Band-pass filtering\n",
        "- to remove noise artifacts (muscle, eye movement and blinking, power line, and interference with other device.)\n",
        "- noises from the biological sinal should be ranged in low frequencies\n",
        "- Power line noise at 50 and 60 Hz\n",
        "\n",
        "### ERD/ERS patterns would be ranged(observed) between 5 - 30 hz\n",
        "- General frequency : 5-30 hz or 8 12 hz\n",
        "- User specific frequency investigated in validation set\n",
        "- Frequency concatenation: [5-30hz] + [8-12hz]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqcTS9bUS4xC"
      },
      "outputs": [],
      "source": [
        "def my_filt(dat, band):    \n",
        "    sos = butter(5, band, 'band', fs=100, output='sos')   \n",
        "    fdat = list()\n",
        "    for i in range(np.size(dat, 1)):\n",
        "        tm = signal.sosfilt(sos, dat[:,i])\n",
        "        fdat.append(tm)  \n",
        "    return np.array(fdat).transpose()\n",
        "\n",
        "tr_flt_cnt = my_filt(tr_cnt_, band)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeJOeaP1S4xD"
      },
      "source": [
        "## Segmentation\n",
        "- Selected time interval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHpTtlxVS4xD"
      },
      "outputs": [],
      "source": [
        "tr_seg = list()\n",
        "for i in range(np.size(tr_Label, 1)):\n",
        "    ival = range(tr_marker[0, i]+interval[0], tr_marker[0, i]+interval[1])\n",
        "    tr_seg.append(tr_flt_cnt[ival, :] ) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbyPNYMlS4xE"
      },
      "source": [
        "## Feature extraction\n",
        "- Log-variance feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "U7oP4nugS4xF"
      },
      "outputs": [],
      "source": [
        "tr_ft_c1 = np.log(np.var(np.array(tr_seg), 1)) [np.where(tr_Label[0,:] == 0)]\n",
        "tr_ft_c2 = np.log(np.var(np.array(tr_seg), 1)) [np.where(tr_Label[0,:] == 1)]\n",
        "\n",
        "plt.scatter(tr_ft_c1[:,ch_name.index('C3')], tr_ft_c1[:,ch_name.index('C4')], c = 'r')\n",
        "plt.scatter(tr_ft_c2[:,ch_name.index('C3')], tr_ft_c2[:,ch_name.index('C4')])\n",
        "\n",
        "plt.xlabel('Dim 12: C3 channel:')\n",
        "plt.ylabel('Dim 14: C4 channel:')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjn2IHcHS4xF"
      },
      "source": [
        "## Classifier\n",
        "- LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNB6X0omS4xG"
      },
      "outputs": [],
      "source": [
        "Y = np.concatenate((np.ones(len(tr_ft_c1)), np.ones(len(tr_ft_c2))+1))\n",
        "clf = LDA()\n",
        "clf.fit(np.concatenate((tr_ft_c1, tr_ft_c2), axis = 0), Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9-IbtilS4xG"
      },
      "source": [
        "## Performance evaluation using the test dataset\n",
        "- Data processing step and parameters the should be the same "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAkxIYqMS4xH"
      },
      "outputs": [],
      "source": [
        "# test dataset load \n",
        "te_flt_cnt = my_filt(te_cnt_, band)\n",
        "\n",
        "te_seg = list()\n",
        "for i in range(np.size(te_Label, 1)):\n",
        "    ival = range(te_marker[0, i]+interval[0], te_marker[0, i]+interval[1])\n",
        "    te_seg.append(te_flt_cnt[ival, :] )\n",
        "    \n",
        "te_ft_c1 = np.log(np.var(np.array(te_seg), 1)) [np.where(te_Label[0,:] == 0)]\n",
        "te_ft_c2 = np.log(np.var(np.array(te_seg), 1)) [np.where(te_Label[0,:] == 1)]\n",
        "\n",
        "Yt = np.concatenate((np.ones(len(te_ft_c1)), np.ones(len(te_ft_c2))+1))\n",
        "clf.predict(np.concatenate((te_ft_c1, te_ft_c2), axis = 0))\n",
        "accuracy_score(Yt, clf.predict(np.concatenate((te_ft_c1, te_ft_c2), axis = 0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIq-rcHtS4xH"
      },
      "source": [
        "# Approach II\n",
        "- Classification results with Spatial filtering - Common Spatial Filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0Zy_BfeS4xI"
      },
      "source": [
        "![csp.JPG](attachment:csp.JPG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMQoyXmrS4xI"
      },
      "source": [
        "Here we already have segmented data:\n",
        "\n",
        "C1: (50, 200, 62)  (trial, data points, channel)\n",
        "\n",
        "permute -> (200, 50, 62)\n",
        "\n",
        "reshape -> (200x50, 62) -> transpose (62, 10000) \n",
        "\n",
        "covariance -> (62, 62)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLm7ORWWS4xI"
      },
      "outputs": [],
      "source": [
        "C1 = np.array(tr_seg)[np.where(tr_Label[0,:] == 0)]\n",
        "C2 = np.array(tr_seg)[np.where(tr_Label[0,:] == 1)]\n",
        "\n",
        "C1 = np.transpose(C1, (1, 0, 2))\n",
        "C2 = np.transpose(C2, (1, 0, 2))\n",
        "\n",
        "C1 = np.reshape(C1, (10000, np.size(C1, 2)))\n",
        "C2 = np.reshape(C2, (10000, np.size(C2, 2)))\n",
        "\n",
        "Cov1 = np.cov(np.transpose(C1))\n",
        "Cov2 = np.cov(np.transpose(C2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "9h5CETBZS4xJ"
      },
      "outputs": [],
      "source": [
        "from scipy.linalg import eigh\n",
        "\n",
        "D, W = eigh(Cov1, Cov1+Cov2)\n",
        "CSP_W = W[:, [0, 1, -2, -1]]\n",
        "\n",
        "CSP_C1 = np.matmul(C1, CSP_W)\n",
        "CSP_C2 = np.matmul(C2, CSP_W)\n",
        "\n",
        "CSP_trft_c1 = np.log(np.var(np.reshape(CSP_C1, (200, 50, 4)), 0))\n",
        "CSP_trft_c2 = np.log(np.var(np.reshape(CSP_C2, (200, 50, 4)), 0))\n",
        "# Classificaiton\n",
        "\n",
        "plt.scatter(CSP_trft_c1[:,0], CSP_trft_c1[:,3], c = 'r')\n",
        "plt.scatter(CSP_trft_c2[:,0], CSP_trft_c2[:,3])\n",
        "\n",
        "plt.xlabel('Dim 1: CSP_1')\n",
        "plt.ylabel('Dim 64: CSP_64')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDVU4d2qS4xJ"
      },
      "source": [
        "![csp2.JPG](attachment:csp2.JPG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxb4hvTZS4xK"
      },
      "outputs": [],
      "source": [
        "CSP_W = W[:, [1, 2, -1, -2]]\n",
        "\n",
        "CSP_C1 = np.matmul(C1, CSP_W)\n",
        "CSP_C2 = np.matmul(C2, CSP_W)\n",
        "\n",
        "CSP_trft_c1 = np.log(np.var(np.reshape(CSP_C1, (200, 50, 4)), 0))\n",
        "CSP_trft_c2 = np.log(np.var(np.reshape(CSP_C2, (200, 50, 4)), 0))\n",
        "# Classificaiton\n",
        "\n",
        "plt.scatter(CSP_trft_c1[:,0], CSP_trft_c1[:,3], c = 'r')\n",
        "plt.scatter(CSP_trft_c2[:,0], CSP_trft_c2[:,3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2n16hrgS4xK"
      },
      "outputs": [],
      "source": [
        "Y = np.concatenate((np.ones(len(CSP_trft_c1)), np.ones(len(CSP_trft_c2))+1))\n",
        "clf = LDA()\n",
        "clf.fit(np.concatenate((CSP_trft_c1, CSP_trft_c2), axis = 0), Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u6aNLn4S4xL"
      },
      "source": [
        "If we use the general parameters, then we do not need a validation dataset. \n",
        "- 8-12 band for all the subject. \n",
        "However, if we want to find user-specific frecuenty bands, then we have to create a validataion dataset\n",
        "- 9-15 for subject 1, 5-20 for subject 2 ...\n",
        "- Training dataset can be divided into training / validation with the specific ratio (50/50). \n",
        "- Cross-validation based on the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STArgo0NS4xL"
      },
      "outputs": [],
      "source": [
        "te_flt_cnt = my_filt(te_cnt_, band)\n",
        "\n",
        "te_seg = list()\n",
        "for i in range(np.size(te_Label, 1)):\n",
        "    ival = range(te_marker[0, i]+interval[0], te_marker[0, i]+interval[1])\n",
        "    te_seg.append(te_flt_cnt[ival, :] )\n",
        "\n",
        "    \n",
        "C1 = np.array(te_seg)[np.where(te_Label[0,:] == 0)]\n",
        "C2 = np.array(te_seg)[np.where(te_Label[0,:] == 1)]\n",
        "\n",
        "C1 = np.transpose(C1, (1, 0, 2))\n",
        "C2 = np.transpose(C2, (1, 0, 2))\n",
        "C1 = np.reshape(C1, (10000, np.size(C1, 2)))\n",
        "C2 = np.reshape(C2, (10000, np.size(C2, 2)))\n",
        "    \n",
        "CSP_C1 = np.matmul(C1, CSP_W)\n",
        "CSP_C2 = np.matmul(C2, CSP_W)\n",
        "\n",
        "CSP_teft_c1 = np.log(np.var(np.reshape(CSP_C1, (200, 50, 4)), 0))\n",
        "CSP_teft_c2 = np.log(np.var(np.reshape(CSP_C2, (200, 50, 4)), 0))\n",
        " \n",
        "Yt = np.concatenate((np.ones(len(CSP_teft_c1)), np.ones(len(CSP_teft_c2))+1))\n",
        "clf.predict(np.concatenate((CSP_teft_c1, CSP_teft_c2), axis = 0))\n",
        "accuracy_score(Yt, clf.predict(np.concatenate((CSP_teft_c1, CSP_teft_c2), axis = 0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHs8U7RZS4xM"
      },
      "source": [
        "## Homework\n",
        "- Here we want to find user specific frequency bands\n",
        "\n",
        "1) Define possible frequency bands ( > 5)\n",
        "\n",
        "2) Investigate the performances according to the frequency bands within the training data\n",
        "\n",
        "3) Find one best frequency band and apply it to the test dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVW4kwz4S4xN"
      },
      "outputs": [],
      "source": [
        "def mi_pipe(dat, label, band = [8 12], ival=[75, 350] , ch = [], csp = [0, 1, -2, -1]):\n",
        "    sos = butter(5, band, 'band', fs=100, output='sos')   \n",
        "    fdat = list()\n",
        "    for i in range(np.size(dat, 1)):\n",
        "        tm = signal.sosfilt(sos, dat[:,i])\n",
        "        fdat.append(tm)  \n",
        "        \n",
        "    tr_seg = list()\n",
        "    for i in range(np.size(tr_Label, 1)):\n",
        "        ival = range(tr_marker[0, i]+interval[0], tr_marker[0, i]+interval[1])\n",
        "        tr_seg.append(tr_flt_cnt[ival, :] ) \n",
        "\n",
        "    \n",
        "    \n",
        "    "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}